lmp_config:
  env:
    # map_size: 100
    # num_waypoints_per_plan: 10000  # set to a large number since we only do open loop for sim
    # max_plan_iter: 1
    # visualize: True
  lmps:
    coder: # high-level interpreter
      name: 'coder'
      heirarchy: 'high'
      # model: 'llama3-8B-instruct-official-fineTuned'
      adapter:  # leave empty if no adapter is used
      max_new_tokens: 512
      # sys_prompts: 'coder_sys_prompt.txt'
      # user_prompts: 'coder_user_prompt.txt'
      load_in_4bit: False

      # test / demo
      model: 'gpt-4'
      sys_prompts: 'test_sys.txt'
      user_prompts: 'test_user.txt'

    planner: # low-level planner
      name: 'planner'
      heirarchy: 'low'
      # model: 'llama3-8B-instruct-official-fineTuned'
      model: 'gpt-4'
      adapter:  # leave empty if no adapter is used
      max_new_tokens: 512
      load_in_4bit: True
      # sys_prompts: 'planner_sys_prompt.txt'
      # user_prompts: 'planner_user_prompt.txt'
      
      # test / demo
      sys_prompts: 'demo_sys.txt'
      user_prompts: 'demo_user.txt'
    
    arm: # low-level executor
      name: 'arm'
      heirarchy: 'low'
      model: 'llama3-8B-instruct-official-fineTuned'
      adapter:  # leave empty if no adapter is used
      max_new_tokens: 512
      load_in_4bit: True
      sys_prompts: 'arm_sys_prompt.txt'
      user_prompts: 'arm_user_prompt.txt'
    
    # test:
    #   name: 'test'
    #   model: 'llama3-8B-instruct-official-fineTuned'
    #   adapter:  # leave empty if no adapter is used
    #   max_new_tokens: 512
    #   load_in_4bit: True
    #   sys_prompts: 'test_sys_prompt.txt'
    #   user_prompts: 'test_user_prompt.txt'